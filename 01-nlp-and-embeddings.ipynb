{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "199cdfb6",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "- undertand how text is processed and analysed\n",
    "\n",
    "# NLP (Natural Language Processing)\n",
    "\n",
    "NLP is analysing and generating text(Language).\n",
    "\n",
    "**analysis:** extract meaning, classify, and transalate \n",
    "**generating:** create text, summarize, and chat\n",
    "\n",
    "\n",
    "\n",
    "### Text Processing\n",
    "\n",
    "**tokens:** the basic text units a language model prcoesses, sometimes words, sometimes parts of words, they may not always be meaningful individually, but the meaning is formed across sequence of tokens.\n",
    "\n",
    "\n",
    "**reference:**\n",
    "\n",
    "[nltk](https://www.nltk.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c524cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d296342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT PREPROCESSING: Tokenization\n",
    "\n",
    "\n",
    "def demo_tokenization():\n",
    "    \n",
    "    text = \"Don't split this! Dr. Smith's email is test@example.com. Cost: $49.99\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Edge cases\n",
    "    print(\"=\"*60)\n",
    "    print(\"EDGE CASES\")\n",
    "\n",
    "\n",
    "    edge_cases = [\n",
    "        \"It's can't won't\",\n",
    "        \"U.S.A. vs USA\",\n",
    "        \"covid-19\",\n",
    "        \"test@email.com\",\n",
    "        \"I'm feeling ðŸ˜Š today!\",\n",
    "    ]\n",
    "    \n",
    "\n",
    "demo_tokenization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e610be5",
   "metadata": {},
   "source": [
    "A better tokenizer handeles contractions, seperated punctuation and kepps meaningful units together\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f1053",
   "metadata": {},
   "source": [
    "### Notmalization\n",
    "\n",
    "sometimes we have tokens that have same surface forms but convety the same underlying meaning, so we normalize them\n",
    "\n",
    "**example:** run, runs, ran, running -> run\n",
    "\n",
    "\n",
    "this is done via:\n",
    "\n",
    "- **Stemming:**\n",
    "- **Lemmatization:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39bc8b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT PREPROCESSING: Normalization\n",
    "\n",
    "def demo_normalization():\n",
    "    \"\"\"Compare stemming and lemmatization\"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "demo_normalization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44e7bc",
   "metadata": {},
   "source": [
    "**STEMMING (Porter Stemmer):**\n",
    "\n",
    "- Fast - just chops off endings\n",
    "- Good for search (retrieval)\n",
    "- Creates non-words: 'caring' â†’ 'care' (good), 'studies' â†’ 'studi' (bad)\n",
    "    \n",
    "**LEMMATIZATION:**\n",
    "- Real words - uses dictionary\n",
    "- Better for analysis\n",
    "- Slower\n",
    "- Needs part-of-speech tag\n",
    "    \n",
    "\n",
    "**WHEN TO USE:**\n",
    "- Search engines â†’ Stemming (speed)\n",
    "- Sentiment analysis â†’ Lemmatization (accuracy)\n",
    "\n",
    "----\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c870687a",
   "metadata": {},
   "source": [
    "### N-grams & Language Modeling\n",
    "\n",
    "until now we processed text now lets predict what comes next in a sentence\n",
    "\n",
    "usecases:\n",
    "\n",
    "- auto complete\n",
    "\n",
    "An n-gram model is based on conditional probability: given the previous words, it estimates what word is likely to occur next.\n",
    "\n",
    "- n=1 (unigram)\n",
    "- n=2 (bigram)\n",
    "- n = 3 (trigram) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf36e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N-GRAMS: Modeling sequences of words\n",
    "# Predicting the next word based on previous words\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "class NGramModel:\n",
    "    \"\"\"\n",
    "    Simple n-gram language model\n",
    "    Predicts next word based on previous n-1 words\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n=2):\n",
    "        \"\"\"\n",
    "        n=1: unigram (no context)\n",
    "        n=2: bigram (previous 1 word)\n",
    "        n=3: trigram (previous 2 words)\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.ngrams = defaultdict(Counter)\n",
    "        self.context_counts = Counter()\n",
    "    \n",
    "    def train(self, text):\n",
    "        \"\"\"Learn n-gram probabilities from text\"\"\"\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        \n",
    "        # Add start/end markers\n",
    "        tokens = ['<START>'] * (self.n - 1) + tokens + ['<END>']\n",
    "        \n",
    "        # Count n-grams\n",
    "        for i in range(len(tokens) - self.n + 1):\n",
    "            # Context: first n-1 words\n",
    "            context = tuple(tokens[i:i + self.n - 1])\n",
    "            # Next word\n",
    "            next_word = tokens[i + self.n - 1]\n",
    "            \n",
    "            self.ngrams[context][next_word] += 1\n",
    "            self.context_counts[context] += 1\n",
    "    \n",
    "    def probability(self, context, word):\n",
    "        \"\"\"P(word | context)\"\"\"\n",
    "        context = tuple(context)\n",
    "        if context not in self.ngrams:\n",
    "            return 0.0\n",
    "        \n",
    "        count = self.ngrams[context][word]\n",
    "        total = self.context_counts[context]\n",
    "        return count / total\n",
    "    \n",
    "    def generate(self, max_words=20):\n",
    "        \"\"\"Generate text using the model\"\"\"\n",
    "        context = ['<START>'] * (self.n - 1)\n",
    "        result = []\n",
    "        \n",
    "        for _ in range(max_words):\n",
    "            # Get possible next words\n",
    "            context_tuple = tuple(context[-(self.n-1):])\n",
    "            \n",
    "            if context_tuple not in self.ngrams:\n",
    "                break\n",
    "            \n",
    "            # Choose next word based on probabilities\n",
    "            next_words = self.ngrams[context_tuple]\n",
    "            next_word = random.choices(\n",
    "                list(next_words.keys()),\n",
    "                weights=list(next_words.values())\n",
    "            )[0]\n",
    "            \n",
    "            if next_word == '<END>':\n",
    "                break\n",
    "            \n",
    "            result.append(next_word)\n",
    "            context.append(next_word)\n",
    "        \n",
    "        return ' '.join(result)\n",
    "\n",
    "\n",
    "def demo_ngrams():\n",
    "    \"\"\"Show n-grams in action\"\"\"\n",
    "    \n",
    "    # Training data: Shakespeare quotes\n",
    "    corpus = \"\"\"\n",
    "    To be or not to be, that is the question.\n",
    "    All the world's a stage, and all the men and women merely players.\n",
    "    To be or not to be, to thine own self be true.\n",
    "    The course of true love never did run smooth.\n",
    "    All that glitters is not gold.\n",
    "    What's in a name? A rose by any other name would smell as sweet.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"N-GRAM LANGUAGE MODELS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nTraining corpus:\\n{corpus[:200]}...\\n\")\n",
    "    \n",
    "    # Train different n-gram models\n",
    "    for n in [2, 3]:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{n}-GRAM MODEL (context = {n-1} words)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        model = NGramModel(n=n)\n",
    "        model.train(corpus)\n",
    "        \n",
    "        # Show some probabilities\n",
    "        if n == 2:\n",
    "            context = ['to']\n",
    "            print(f\"\\nProbabilities after '{context[0]}':\")\n",
    "            for word, count in model.ngrams[tuple(context)].most_common(5):\n",
    "                prob = model.probability(context, word)\n",
    "                print(f\"  P({word} | {context[0]}) = {prob:.3f}\")\n",
    "        \n",
    "        # Generate text\n",
    "        print(f\"\\nGenerated text:\")\n",
    "        for i in range(3):\n",
    "            print(f\"  {i+1}. {model.generate()}\")\n",
    "demo_ngrams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13ee056",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- Bigrams capture local patterns\n",
    "- Trigrams more coherent but need more data\n",
    "- Still nonsensical - no real understanding\n",
    "- Can only use patterns seen in training (data sparicty problem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bb1a8b",
   "metadata": {},
   "source": [
    "### Activity\n",
    "\n",
    "experiment with your own n-gram\n",
    "\n",
    "[n-gram](./n-gram-experiment.py)\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb1ae55",
   "metadata": {},
   "source": [
    "N-grams predict the next word. But what if we want to classify an entire document, like 'is this review positive or negative?' We need a different approach.\n",
    "\n",
    "\n",
    "#### Bag of Words & Classification\n",
    "\n",
    "from sequences to documents\n",
    "\n",
    "one-hot encode the each token and sum them across the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10b06cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAG OF WORDS: Representing documents as word counts\n",
    "# Ignore order, just count presence\n",
    "\n",
    "def demo_bow():\n",
    "    \"\"\"Visualize bag of words representation\"\"\"\n",
    "    \n",
    "demo_bow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae601e",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "- Each document is now a vector of word counts\n",
    "- Same length (vocabulary size)\n",
    "- Can now use machine learning\n",
    "    \n",
    "- Lost word order: \"dog bites man\" = \"man bites dog\"\n",
    "- Lost syntax: \"not good\" looks like \"good\"\n",
    "- Every word is a separate dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beccfdac",
   "metadata": {},
   "source": [
    "**1. TEXT PREPROCESSING**\n",
    "\n",
    "- Tokenization: Breaking text into words\n",
    "- Normalization: Stemming/lemmatization\n",
    "- These are fundamental to all NLP\n",
    "    \n",
    "**2. N-GRAMS**\n",
    "\n",
    "- Model probability of word sequences\n",
    "- Predict next word\n",
    "- Can't generalize to unseen sequences\n",
    "- Data sparsity problem\n",
    "    \n",
    "**3. BAG OF WORDS + CLASSIFICATION**\n",
    "- Represent documents as vectors\n",
    "- Train classifiers (logistic regression)\n",
    "- Each word is separate dimension\n",
    "- Synonyms are invisible\n",
    "- Vocabulary explosion (50,000+ dimensions)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "current representation does not consider car and automobile as same thing \n",
    "\n",
    "'car'        â†’ [0, 0, 1, 0, 0, ...]  (50,000 dimensions)\n",
    "'automobile' â†’ [0, 1, 0, 0, 0, ...]  (completely different!)\n",
    "\n",
    "\n",
    "so sparse vectors are not enough to identify the synonyms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a6855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
